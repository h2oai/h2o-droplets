/*
 * This is a simple build file for building Sparkling Water applications.
 *
 * For more details please follow README.md.
 */

// Apply the java plugin to add support for Java
apply plugin: 'scala'
apply plugin: 'java-library'
// Support local launch of application 
apply plugin: 'application'
mainClassName = 'water.droplets.SparklingWaterDroplet'
//
// The build script settings to fetch plugins and put them on
// classpath
buildscript {
    repositories {
        mavenCentral()
        jcenter()
    }

    dependencies {
        classpath 'com.github.jengelman.gradle.plugins:shadow:6.0.0'
        classpath 'org.github.ngbinh.scalastyle:gradle-scalastyle-plugin_2.11:1.0.1'
    }
}

//
// Configure project properties
//
ext {
    // Spark version
    sparkVersion = "3.0.0"
    // Latest stable version for the specified version of Spark
    spWaterVersion = "3.30.0.7-1-3.0"

    // Scala binary version
    scalaBaseVersion = '2.12'
    scalaVersion = '2.12.10'
}

java {
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}


// In this section you declare where to find the dependencies of your project
repositories {
    // Use 'maven central' for resolving your dependencies.
    // You can declare any Maven/Ivy/file repository here.
    mavenCentral()

    // Cloudera dependencies
    maven {
        url "https://repository.cloudera.com/artifactory/cloudera-repos/"
    }

    // Hortonworks dependencies
    maven {
        url "https://repo.hortonworks.com/content/repositories/releases/"
    }

    // Public sonatype repository
    maven {
        url "https://oss.sonatype.org/content/repositories/releases/"
    }

    // Enable 'maven local' for resolving your locally cached dependencies
    // Useful for cross development for example with h2o-dev
    if (spWaterVersion.endsWith("SNAPSHOT")) mavenLocal()
}

// This section declares the dependencies for your production and test code
dependencies {
    // Spark Core
    api("org.apache.spark:spark-core_${scalaBaseVersion}:${sparkVersion}")
    // Spark Core
    api("org.apache.spark:spark-repl_${scalaBaseVersion}:${sparkVersion}")
    // Spark SQL
    api("org.apache.spark:spark-sql_${scalaBaseVersion}:${sparkVersion}")
    // Spark MLLib
    api("org.apache.spark:spark-mllib_${scalaBaseVersion}:${sparkVersion}")
    // Spark Streaming
    api("org.apache.spark:spark-streaming_${scalaBaseVersion}:${sparkVersion}")

    // Sparkling Water
    api("ai.h2o:sparkling-water-package_${scalaBaseVersion}:${spWaterVersion}")

    // Scala project needs dependency on Scala library
    api("org.scala-lang:scala-library:$scalaVersion")

    // And use scalatest for Scala testing
    testImplementation("org.scalatest:scalatest_${scalaBaseVersion}:3.2.0")
}

//
// Project specific settings
//

// Setup group ID for this project
group = "ai.h2o"

//
// Setup Scala plugin
//

// Activate Zinc compiler and configure scalac
tasks.withType(ScalaCompile) {
    scalaCompileOptions.additionalParameters = [
            "-target:jvm-1.8",
            "-feature",
            // enable several optional scala features so Scala knows we use them on purpose
            "-language:reflectiveCalls",
            "-language:postfixOps",
            "-language:existentials",
            "-language:implicitConversions",
    ]
}

// In resulting jar include Scala binary version
jar {
    archivesBaseName = "${project.name}_${scalaBaseVersion}"
}

// Check Scala coding conventions
apply from: 'gradle/scalastyle.gradle'

//
// Configure assembly to create Spark application
//

// Support for application assembly
apply plugin: 'com.github.johnrengelman.shadow'


configurations {
    shadowApi {
        extendsFrom api
    }
}

shadowJar {
    // Configure name of output jar as sparkling-water-droplet-app.jar
    archiveAppendix = 'app'
    configurations = [project.configurations.shadowApi]
    mergeServiceFiles()
    archiveBaseName = "${archiveBaseName}_${scalaBaseVersion}"
    zip64 = true
}

artifacts {
    api shadowJar
}
